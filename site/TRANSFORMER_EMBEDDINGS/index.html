
<!doctype html>
<html lang="de" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Einheitliche UDS3 Doku mit API-Referenz und Leitf√§den">
      
      
      
        <link rel="canonical" href="https://makr-code.github.io/VCC-UDS3/TRANSFORMER_EMBEDDINGS/">
      
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.23">
    
    
      
        <title>UDS3 Transformer Embeddings - VCC UDS3 Dokumentation</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.84d31ad4.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#uds3-transformer-embeddings" class="md-skip">
          Zum Inhalt
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Kopfzeile">
    <a href=".." title="VCC UDS3 Dokumentation" class="md-header__button md-logo" aria-label="VCC UDS3 Dokumentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            VCC UDS3 Dokumentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              UDS3 Transformer Embeddings
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Suche" placeholder="Suche" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Suche">
        
        <button type="reset" class="md-search__icon md-icon" title="Zur√ºcksetzen" aria-label="Zur√ºcksetzen" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Suche wird initialisiert
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/makr-code/VCC-UDS3" title="Zum Repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    makr-code/VCC-UDS3
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Hauptnavigation" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../index.md" class="md-tabs__link">
        
  
  
    
  
  Start

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../api/" class="md-tabs__link">
          
  
  
  API-Referenz

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="VCC UDS3 Dokumentation" class="md-nav__button md-logo" aria-label="VCC UDS3 Dokumentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    VCC UDS3 Dokumentation
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/makr-code/VCC-UDS3" title="Zum Repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    makr-code/VCC-UDS3
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../index.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Start
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    API-Referenz
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            API-Referenz
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    √úbersicht
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Inhaltsverzeichnis">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Inhaltsverzeichnis
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      üìã Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#quick-start" class="md-nav__link">
    <span class="md-ellipsis">
      üöÄ Quick Start
    </span>
  </a>
  
    <nav class="md-nav" aria-label="üöÄ Quick Start">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#basic-usage" class="md-nav__link">
    <span class="md-ellipsis">
      Basic Usage
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singleton-pattern" class="md-nav__link">
    <span class="md-ellipsis">
      Singleton Pattern
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#chromadb-integration" class="md-nav__link">
    <span class="md-ellipsis">
      ChromaDB Integration
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#configuration" class="md-nav__link">
    <span class="md-ellipsis">
      üîß Configuration
    </span>
  </a>
  
    <nav class="md-nav" aria-label="üîß Configuration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#environment-variables" class="md-nav__link">
    <span class="md-ellipsis">
      Environment Variables
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#configuration-in-code" class="md-nav__link">
    <span class="md-ellipsis">
      Configuration in Code
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#performance" class="md-nav__link">
    <span class="md-ellipsis">
      üìä Performance
    </span>
  </a>
  
    <nav class="md-nav" aria-label="üìä Performance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#benchmarks-intel-i7-16gb-ram" class="md-nav__link">
    <span class="md-ellipsis">
      Benchmarks (Intel i7, 16GB RAM)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#memory-usage" class="md-nav__link">
    <span class="md-ellipsis">
      Memory Usage
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#testing" class="md-nav__link">
    <span class="md-ellipsis">
      üß™ Testing
    </span>
  </a>
  
    <nav class="md-nav" aria-label="üß™ Testing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#run-all-tests" class="md-nav__link">
    <span class="md-ellipsis">
      Run All Tests
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test-coverage" class="md-nav__link">
    <span class="md-ellipsis">
      Test Coverage
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#api-reference" class="md-nav__link">
    <span class="md-ellipsis">
      üîç API Reference
    </span>
  </a>
  
    <nav class="md-nav" aria-label="üîç API Reference">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#transformerembeddings-class" class="md-nav__link">
    <span class="md-ellipsis">
      TransformerEmbeddings Class
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#helper-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Helper Functions
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#advanced-usage" class="md-nav__link">
    <span class="md-ellipsis">
      üõ†Ô∏è Advanced Usage
    </span>
  </a>
  
    <nav class="md-nav" aria-label="üõ†Ô∏è Advanced Usage">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#custom-model" class="md-nav__link">
    <span class="md-ellipsis">
      Custom Model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fallback-detection" class="md-nav__link">
    <span class="md-ellipsis">
      Fallback Detection
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#semantic-similarity" class="md-nav__link">
    <span class="md-ellipsis">
      Semantic Similarity
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#batch-processing-best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Processing Best Practices
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#thread-safety" class="md-nav__link">
    <span class="md-ellipsis">
      üîí Thread Safety
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#troubleshooting" class="md-nav__link">
    <span class="md-ellipsis">
      ‚ö†Ô∏è Troubleshooting
    </span>
  </a>
  
    <nav class="md-nav" aria-label="‚ö†Ô∏è Troubleshooting">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model-download-fails" class="md-nav__link">
    <span class="md-ellipsis">
      Model Download Fails
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-out-of-memory" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA Out of Memory
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fallback-mode-always-active" class="md-nav__link">
    <span class="md-ellipsis">
      Fallback Mode Always Active
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#poor-semantic-search-quality" class="md-nav__link">
    <span class="md-ellipsis">
      Poor Semantic Search Quality
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#migration-guide-from-hash-based" class="md-nav__link">
    <span class="md-ellipsis">
      üìù Migration Guide (from Hash-Based)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="üìù Migration Guide (from Hash-Based)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#before-hash-based-fake-vectors" class="md-nav__link">
    <span class="md-ellipsis">
      Before (Hash-Based Fake Vectors)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#after-real-embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      After (Real Embeddings)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#chromadb-backend-update" class="md-nav__link">
    <span class="md-ellipsis">
      ChromaDB Backend Update
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      üéØ Best Practices
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    <span class="md-ellipsis">
      üìö References
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#support" class="md-nav__link">
    <span class="md-ellipsis">
      üìû Support
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/makr-code/VCC-UDS3/edit/master/docs/TRANSFORMER_EMBEDDINGS.md" title="Seite editieren" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  


<h1 id="uds3-transformer-embeddings">UDS3 Transformer Embeddings<a class="headerlink" href="#uds3-transformer-embeddings" title="Permanent link">&para;</a></h1>
<p><strong>Version:</strong> 2.1.0<br />
<strong>Erstellt:</strong> 20. Oktober 2025<br />
<strong>Status:</strong> ‚úÖ Production Ready</p>
<hr />
<h2 id="overview">üìã Overview<a class="headerlink" href="#overview" title="Permanent link">&para;</a></h2>
<p>UDS3 v2.1.0 introduces <strong>real semantic embeddings</strong> using <code>sentence-transformers</code>. This replaces hash-based fake vectors with true semantic representations for ChromaDB vector storage.</p>
<p><strong>Key Features:</strong>
- ‚úÖ <strong>Real Semantic Embeddings</strong> (384-dim, multilingual)
- ‚úÖ <strong>Lazy Loading</strong> (model loaded only when needed)
- ‚úÖ <strong>Thread-Safe</strong> (double-check locking pattern)
- ‚úÖ <strong>GPU Acceleration</strong> (CUDA auto-detect)
- ‚úÖ <strong>Fallback Mode</strong> (hash-based vectors if model fails)
- ‚úÖ <strong>Batch Processing</strong> (2-5x faster than sequential)
- ‚úÖ <strong>ENV Configuration</strong> (model selection, device control)</p>
<hr />
<h2 id="quick-start">üöÄ Quick Start<a class="headerlink" href="#quick-start" title="Permanent link">&para;</a></h2>
<h3 id="basic-usage">Basic Usage<a class="headerlink" href="#basic-usage" title="Permanent link">&para;</a></h3>
<pre><code class="language-python">from uds3.embeddings import TransformerEmbeddings

# Create embedder (lazy loading)
embedder = TransformerEmbeddings()

# Generate single embedding
text = &quot;This is a legal contract for software development.&quot;
vector = embedder.embed(text)  # Returns List[float] (384-dim)

# Batch processing (2-5x faster)
texts = [&quot;Contract text 1&quot;, &quot;Contract text 2&quot;, &quot;Contract text 3&quot;]
vectors = embedder.embed_batch(texts)  # Returns List[List[float]]

# Check dimensions
dims = embedder.get_dimensions()  # Returns 384

# Check fallback mode
if embedder.is_fallback_mode():
    print(&quot;‚ö†Ô∏è Using hash-based fallback&quot;)
</code></pre>
<h3 id="singleton-pattern">Singleton Pattern<a class="headerlink" href="#singleton-pattern" title="Permanent link">&para;</a></h3>
<pre><code class="language-python">from uds3.embeddings import get_default_embeddings

# Get global singleton instance
embedder = get_default_embeddings()
vector = embedder.embed(&quot;Some text&quot;)
</code></pre>
<h3 id="chromadb-integration">ChromaDB Integration<a class="headerlink" href="#chromadb-integration" title="Permanent link">&para;</a></h3>
<pre><code class="language-python">from uds3.database.database_api_chromadb_remote import ChromaRemoteVectorBackend

# ChromaDB backend with auto-embedding
chromadb = ChromaRemoteVectorBackend(config)

# Add vector WITH auto-embedding from text
chromadb.add_vector(
    vector=None,  # Will be generated from text!
    metadata={&quot;doc_id&quot;: &quot;123&quot;, &quot;chunk_index&quot;: 0},
    doc_id=&quot;chunk_123_0&quot;,
    text=&quot;Legal contract text...&quot;  # ‚Üê Auto-embedded!
)

# Or provide pre-computed vector (backward compatible)
chromadb.add_vector(
    vector=[0.1, 0.2, ...],  # Pre-computed
    metadata={&quot;doc_id&quot;: &quot;123&quot;},
    doc_id=&quot;chunk_123_0&quot;
)
</code></pre>
<hr />
<h2 id="configuration">üîß Configuration<a class="headerlink" href="#configuration" title="Permanent link">&para;</a></h2>
<h3 id="environment-variables">Environment Variables<a class="headerlink" href="#environment-variables" title="Permanent link">&para;</a></h3>
<pre><code class="language-bash"># Enable/Disable Real Embeddings (default: true)
ENABLE_REAL_EMBEDDINGS=true

# Model Selection (default: all-MiniLM-L6-v2)
EMBEDDING_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
# Alternatives:
# - all-mpnet-base-v2 (768-dim, higher quality, slower)
# - paraphrase-multilingual-MiniLM-L12-v2 (384-dim, better multilingual)
# - distilbert-base-nli-mean-tokens (768-dim, fast)

# Device Selection (default: auto-detect)
EMBEDDING_DEVICE=auto
# Options: auto, cuda, cpu
# auto ‚Üí uses CUDA if available, else CPU
</code></pre>
<h3 id="configuration-in-code">Configuration in Code<a class="headerlink" href="#configuration-in-code" title="Permanent link">&para;</a></h3>
<pre><code class="language-python">import os

# Disable real embeddings (use hash fallback)
os.environ['ENABLE_REAL_EMBEDDINGS'] = 'false'

# Force CPU (even if CUDA available)
os.environ['EMBEDDING_DEVICE'] = 'cpu'

# Use different model
os.environ['EMBEDDING_MODEL_NAME'] = 'all-mpnet-base-v2'

from uds3.embeddings import TransformerEmbeddings
embedder = TransformerEmbeddings()  # Will use ENV config
</code></pre>
<hr />
<h2 id="performance">üìä Performance<a class="headerlink" href="#performance" title="Permanent link">&para;</a></h2>
<h3 id="benchmarks-intel-i7-16gb-ram">Benchmarks (Intel i7, 16GB RAM)<a class="headerlink" href="#benchmarks-intel-i7-16gb-ram" title="Permanent link">&para;</a></h3>
<p><strong>Single Embedding:</strong></p>
<pre><code>CPU (all-MiniLM-L6-v2):    ~40ms per text
GPU (CUDA):                ~10ms per text
Hash Fallback:             ~1ms per text
</code></pre>
<p><strong>Batch Embedding (10 texts):</strong></p>
<pre><code>Sequential CPU:  ~400ms  (10x ~40ms)
Batch CPU:       ~160ms  (2.5x speedup)
Batch GPU:       ~50ms   (8x speedup)
</code></pre>
<p><strong>Model Loading (First Use):</strong></p>
<pre><code>all-MiniLM-L6-v2:          ~2.2s (one-time, lazy)
all-mpnet-base-v2:         ~5.0s (one-time, lazy)
</code></pre>
<h3 id="memory-usage">Memory Usage<a class="headerlink" href="#memory-usage" title="Permanent link">&para;</a></h3>
<pre><code>Model in RAM (CPU):        ~90MB
Model in VRAM (GPU):       ~120MB
Per 384-dim vector:        ~1.5KB (float32)
</code></pre>
<hr />
<h2 id="testing">üß™ Testing<a class="headerlink" href="#testing" title="Permanent link">&para;</a></h2>
<h3 id="run-all-tests">Run All Tests<a class="headerlink" href="#run-all-tests" title="Permanent link">&para;</a></h3>
<pre><code class="language-bash">cd /path/to/uds3
python -m pytest tests/test_transformer_embeddings.py -v
</code></pre>
<p><strong>Expected Output:</strong></p>
<pre><code>tests/test_transformer_embeddings.py::TestTransformerEmbeddings::test_lazy_loading PASSED
tests/test_transformer_embeddings.py::TestTransformerEmbeddings::test_thread_safe_loading PASSED
... (17 tests total)
============================= 17 passed in 10.08s =============================
</code></pre>
<h3 id="test-coverage">Test Coverage<a class="headerlink" href="#test-coverage" title="Permanent link">&para;</a></h3>
<p><strong>17 Test Cases (100% PASS):</strong>
- ‚úÖ Lazy loading (model not loaded until first use)
- ‚úÖ Thread-safe initialization (10 concurrent threads)
- ‚úÖ 384-dim vector generation
- ‚úÖ Deterministic embeddings (same text ‚Üí same vector)
- ‚úÖ Different texts ‚Üí different vectors
- ‚úÖ Batch embedding (3 documents)
- ‚úÖ Batch performance (1.5x faster)
- ‚úÖ Fallback mode detection
- ‚úÖ Hash-based fallback (384-dim normalized [0,1])
- ‚úÖ get_dimensions() returns 384
- ‚úÖ Semantic similarity (cat/mat &gt; cat/python)
- ‚úÖ Singleton pattern
- ‚úÖ Empty text handling
- ‚úÖ Long text handling (10,000 chars)
- ‚úÖ Special characters (√§√∂√º √ü ‚Ç¨@#$%)
- ‚úÖ Unicode support (English, Deutsch, ‰∏≠Êñá, Êó•Êú¨Ë™û, ÌïúÍµ≠Ïñ¥)</p>
<hr />
<h2 id="api-reference">üîç API Reference<a class="headerlink" href="#api-reference" title="Permanent link">&para;</a></h2>
<h3 id="transformerembeddings-class">TransformerEmbeddings Class<a class="headerlink" href="#transformerembeddings-class" title="Permanent link">&para;</a></h3>
<pre><code class="language-python">class TransformerEmbeddings:
    &quot;&quot;&quot;
    Sentence Transformer embeddings with lazy loading and fallback

    Features:
    - Lazy loading (model loaded on first use)
    - Thread-safe initialization
    - GPU acceleration (CUDA auto-detect)
    - Fallback to hash-based vectors on error
    - Batch processing support

    Examples:
        &gt;&gt;&gt; embedder = TransformerEmbeddings()
        &gt;&gt;&gt; vector = embedder.embed(&quot;Some text&quot;)
        &gt;&gt;&gt; len(vector)
        384
    &quot;&quot;&quot;

    def __init__(
        self,
        model_name: str = None,
        device: str = None
    ):
        &quot;&quot;&quot;
        Initialize embedder (model NOT loaded yet - lazy!)

        Args:
            model_name: Model name (default: from ENV or all-MiniLM-L6-v2)
            device: Device to use (default: from ENV or auto-detect)
        &quot;&quot;&quot;

    def embed(self, text: str) -&gt; List[float]:
        &quot;&quot;&quot;
        Generate embedding for single text

        Args:
            text: Input text (any length)

        Returns:
            384-dim vector (List[float])

        Note:
            First call loads model (lazy loading, ~2s overhead)
            Subsequent calls are fast (~40ms CPU, ~10ms GPU)
        &quot;&quot;&quot;

    def embed_batch(self, texts: List[str]) -&gt; List[List[float]]:
        &quot;&quot;&quot;
        Generate embeddings for multiple texts (faster!)

        Args:
            texts: List of input texts

        Returns:
            List of 384-dim vectors

        Performance:
            2-5x faster than sequential embed() calls
            Recommended for &gt;3 texts
        &quot;&quot;&quot;

    def get_dimensions(self) -&gt; int:
        &quot;&quot;&quot;
        Get embedding dimensions

        Returns:
            384 (for all-MiniLM-L6-v2)
            768 (for all-mpnet-base-v2)
        &quot;&quot;&quot;

    def is_fallback_mode(self) -&gt; bool:
        &quot;&quot;&quot;
        Check if using hash-based fallback

        Returns:
            True if fallback active (no semantic meaning!)
            False if using real model
        &quot;&quot;&quot;
</code></pre>
<h3 id="helper-functions">Helper Functions<a class="headerlink" href="#helper-functions" title="Permanent link">&para;</a></h3>
<pre><code class="language-python">def load_embedding_model(
    model_name: str = None,
    device: str = None
) -&gt; Optional[SentenceTransformer]:
    &quot;&quot;&quot;
    Load sentence transformer model (thread-safe)

    Args:
        model_name: Model name (default: all-MiniLM-L6-v2)
        device: Device (default: auto-detect CUDA)

    Returns:
        SentenceTransformer instance or None on error

    Note:
        Uses double-check locking for thread safety
        First call downloads model (~90MB)
        Subsequent calls load from cache
    &quot;&quot;&quot;

def get_default_embeddings() -&gt; TransformerEmbeddings:
    &quot;&quot;&quot;
    Get global singleton embedder

    Returns:
        TransformerEmbeddings instance (shared across app)

    Use Case:
        When multiple components need same embedder
        Avoids loading model multiple times
    &quot;&quot;&quot;
</code></pre>
<hr />
<h2 id="advanced-usage">üõ†Ô∏è Advanced Usage<a class="headerlink" href="#advanced-usage" title="Permanent link">&para;</a></h2>
<h3 id="custom-model">Custom Model<a class="headerlink" href="#custom-model" title="Permanent link">&para;</a></h3>
<pre><code class="language-python">from uds3.embeddings import TransformerEmbeddings

# Use larger, more accurate model (768-dim)
embedder = TransformerEmbeddings(
    model_name=&quot;all-mpnet-base-v2&quot;,
    device=&quot;cuda&quot;  # Force GPU
)

vector = embedder.embed(&quot;Legal text&quot;)
print(len(vector))  # 768 (not 384!)
</code></pre>
<h3 id="fallback-detection">Fallback Detection<a class="headerlink" href="#fallback-detection" title="Permanent link">&para;</a></h3>
<pre><code class="language-python">from uds3.embeddings import TransformerEmbeddings

embedder = TransformerEmbeddings()
vector = embedder.embed(&quot;Some text&quot;)

if embedder.is_fallback_mode():
    print(&quot;‚ö†Ô∏è WARNING: Using hash-based fallback!&quot;)
    print(&quot;‚Üí No semantic similarity search possible&quot;)
    print(&quot;‚Üí Check logs for model loading error&quot;)
else:
    print(&quot;‚úÖ Using real semantic embeddings&quot;)
</code></pre>
<h3 id="semantic-similarity">Semantic Similarity<a class="headerlink" href="#semantic-similarity" title="Permanent link">&para;</a></h3>
<pre><code class="language-python">from uds3.embeddings import TransformerEmbeddings
import numpy as np

embedder = TransformerEmbeddings()

# Compare two texts
text1 = &quot;The cat sat on the mat&quot;
text2 = &quot;A feline rested on the rug&quot;
text3 = &quot;Python is a programming language&quot;

v1 = embedder.embed(text1)
v2 = embedder.embed(text2)
v3 = embedder.embed(text3)

# Cosine similarity
def cosine_sim(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

print(f&quot;cat/mat vs feline/rug: {cosine_sim(v1, v2):.3f}&quot;)  # ~0.85 (high!)
print(f&quot;cat/mat vs Python:     {cosine_sim(v1, v3):.3f}&quot;)  # ~0.15 (low)
</code></pre>
<h3 id="batch-processing-best-practices">Batch Processing Best Practices<a class="headerlink" href="#batch-processing-best-practices" title="Permanent link">&para;</a></h3>
<pre><code class="language-python">from uds3.embeddings import TransformerEmbeddings

embedder = TransformerEmbeddings()

# ‚úÖ GOOD: Batch processing for multiple texts
chunks = [&quot;chunk1&quot;, &quot;chunk2&quot;, &quot;chunk3&quot;, ...]  # 100 chunks
vectors = embedder.embed_batch(chunks)  # ~2s (CPU)

# ‚ùå BAD: Sequential processing
vectors = []
for chunk in chunks:
    vectors.append(embedder.embed(chunk))  # ~4s (CPU) - 2x slower!
</code></pre>
<hr />
<h2 id="thread-safety">üîí Thread Safety<a class="headerlink" href="#thread-safety" title="Permanent link">&para;</a></h2>
<p><strong>TransformerEmbeddings is fully thread-safe:</strong></p>
<pre><code class="language-python">from uds3.embeddings import get_default_embeddings
from concurrent.futures import ThreadPoolExecutor

# Shared embedder across threads
embedder = get_default_embeddings()

def process_document(doc_text):
    return embedder.embed(doc_text)

# Parallel processing (safe!)
with ThreadPoolExecutor(max_workers=10) as executor:
    results = executor.map(process_document, document_list)
</code></pre>
<p><strong>Locking Strategy:</strong>
- Model loading uses double-check locking
- embed() is thread-safe (no shared state)
- embed_batch() is thread-safe</p>
<hr />
<h2 id="troubleshooting">‚ö†Ô∏è Troubleshooting<a class="headerlink" href="#troubleshooting" title="Permanent link">&para;</a></h2>
<h3 id="model-download-fails">Model Download Fails<a class="headerlink" href="#model-download-fails" title="Permanent link">&para;</a></h3>
<p><strong>Problem:</strong> First run fails with network error</p>
<p><strong>Solution:</strong></p>
<pre><code class="language-bash"># Pre-download model manually
python -c &quot;
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('all-MiniLM-L6-v2')
&quot;
</code></pre>
<h3 id="cuda-out-of-memory">CUDA Out of Memory<a class="headerlink" href="#cuda-out-of-memory" title="Permanent link">&para;</a></h3>
<p><strong>Problem:</strong> GPU runs out of memory with large batches</p>
<p><strong>Solution:</strong></p>
<pre><code class="language-python"># Reduce batch size or force CPU
os.environ['EMBEDDING_DEVICE'] = 'cpu'
</code></pre>
<h3 id="fallback-mode-always-active">Fallback Mode Always Active<a class="headerlink" href="#fallback-mode-always-active" title="Permanent link">&para;</a></h3>
<p><strong>Problem:</strong> <code>is_fallback_mode()</code> always returns True</p>
<p><strong>Check:</strong></p>
<pre><code class="language-python"># 1. Check if sentence-transformers installed
pip list | grep sentence-transformers

# 2. Check ENV variable
print(os.getenv('ENABLE_REAL_EMBEDDINGS'))  # Should be 'true'

# 3. Check logs for error
# Look for: &quot;‚ö†Ô∏è sentence-transformers not available&quot;
</code></pre>
<h3 id="poor-semantic-search-quality">Poor Semantic Search Quality<a class="headerlink" href="#poor-semantic-search-quality" title="Permanent link">&para;</a></h3>
<p><strong>Problem:</strong> Similar texts get low similarity scores</p>
<p><strong>Check:</strong>
1. Verify NOT in fallback mode: <code>embedder.is_fallback_mode()</code> ‚Üí False
2. Try larger model: <code>all-mpnet-base-v2</code> (better quality)
3. Check language: Use multilingual model for non-English texts</p>
<hr />
<h2 id="migration-guide-from-hash-based">üìù Migration Guide (from Hash-Based)<a class="headerlink" href="#migration-guide-from-hash-based" title="Permanent link">&para;</a></h2>
<h3 id="before-hash-based-fake-vectors">Before (Hash-Based Fake Vectors)<a class="headerlink" href="#before-hash-based-fake-vectors" title="Permanent link">&para;</a></h3>
<pre><code class="language-python"># OLD: ingestion_backend.py
chunk_hash = hashlib.md5(chunk.encode()).hexdigest()
fake_vector = [float(int(chunk_hash[i:i+2], 16)) / 255.0 
               for i in range(0, 384*2, 2)]
# ‚Üí No semantic meaning!
</code></pre>
<h3 id="after-real-embeddings">After (Real Embeddings)<a class="headerlink" href="#after-real-embeddings" title="Permanent link">&para;</a></h3>
<pre><code class="language-python"># NEW: Using UDS3 embeddings
from uds3.embeddings import get_default_embeddings

embedder = get_default_embeddings()
real_vector = embedder.embed(chunk)  # ‚úÖ Real semantic meaning!
</code></pre>
<h3 id="chromadb-backend-update">ChromaDB Backend Update<a class="headerlink" href="#chromadb-backend-update" title="Permanent link">&para;</a></h3>
<pre><code class="language-python"># Automatic embedding generation
chromadb.add_vector(
    vector=None,  # Don't provide vector
    metadata=metadata,
    doc_id=chunk_id,
    text=chunk_text  # Provide text instead!
)
# ‚Üí Backend generates embedding automatically
</code></pre>
<hr />
<h2 id="best-practices">üéØ Best Practices<a class="headerlink" href="#best-practices" title="Permanent link">&para;</a></h2>
<ol>
<li>
<p><strong>Use Singleton for Multiple Components:</strong>
   <code>python
   from uds3.embeddings import get_default_embeddings
   embedder = get_default_embeddings()  # Shared instance</code></p>
</li>
<li>
<p><strong>Batch Process When Possible:</strong>
   ```python
   # ‚úÖ Batch (2-5x faster)
   vectors = embedder.embed_batch(texts)</p>
</li>
</ol>
<p># ‚ùå Sequential (slower)
   vectors = [embedder.embed(t) for t in texts]
   ```</p>
<ol>
<li>
<p><strong>Check Fallback Mode in Production:</strong>
   <code>python
   if embedder.is_fallback_mode():
       logger.error("‚ùå CRITICAL: Semantic search unavailable!")</code></p>
</li>
<li>
<p><strong>GPU for High Throughput:</strong>
   <code>bash
   export EMBEDDING_DEVICE=cuda  # If CUDA available</code></p>
</li>
<li>
<p><strong>Monitor Model Loading:</strong>
   <code>python
   import time
   start = time.time()
   vector = embedder.embed("first text")  # Triggers lazy load
   print(f"Model loaded in {time.time() - start:.2f}s")</code></p>
</li>
</ol>
<hr />
<h2 id="references">üìö References<a class="headerlink" href="#references" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>sentence-transformers:</strong> https://www.sbert.net/</li>
<li><strong>all-MiniLM-L6-v2:</strong> https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2</li>
<li><strong>CUDA Setup:</strong> https://pytorch.org/get-started/locally/</li>
</ul>
<hr />
<h2 id="support">üìû Support<a class="headerlink" href="#support" title="Permanent link">&para;</a></h2>
<p><strong>Issues:</strong> UDS3 GitHub Issues<br />
<strong>Questions:</strong> UDS3 Team<br />
<strong>Performance:</strong> Load Testing Team</p>
<hr />
<p><strong>Status:</strong> ‚úÖ <strong>PRODUCTION READY</strong> (v2.1.0)</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Zur√ºck zum Seitenanfang
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["navigation.tabs", "navigation.sections", "navigation.top", "content.code.copy", "content.action.edit", "toc.follow"], "search": "../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "In Zwischenablage kopiert", "clipboard.copy": "In Zwischenablage kopieren", "search.result.more.one": "1 weiteres Suchergebnis auf dieser Seite", "search.result.more.other": "# weitere Suchergebnisse auf dieser Seite", "search.result.none": "Keine Suchergebnisse", "search.result.one": "1 Suchergebnis", "search.result.other": "# Suchergebnisse", "search.result.placeholder": "Suchbegriff eingeben", "search.result.term.missing": "Es fehlt", "select.version": "Version ausw\u00e4hlen"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>